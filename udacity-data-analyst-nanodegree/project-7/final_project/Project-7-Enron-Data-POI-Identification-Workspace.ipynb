{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "> Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to build an efficient machine learning algorithm to programatically detect potential persons of interest within data. The model is expected to make the best use of available features withing Enron Dataset as well as creating new features to predict the poi from the available features. \n",
    "\n",
    "Enron data has 146 data points, 18 of which belong POIs. Each datapoint has 14 features. Features cover a wide variety of data from financial attributes like salary, bonuses, payments to email statistics like emails to POI, and emails from POI. \n",
    "\n",
    "Dataset has one outlier data which belongs to an entry named \"TOTAL\". This entry clearly points to the subtotal for the entire dataset, and thereby should be discarded. Discaridng this entry leaves 18 POI and 127 non-POI entries. With 12.4% POI within dataset, data is skewed towards non-POIs. We should keep an eye on this insight during score extractions from models. Assuming we are primarily concerned with detecting as many POIs as possible, recall will be the primary score we will be looking to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "> What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of variables was within acecptable range, I started with the full set to decide on an model parameters. Later on I was planning on reducing number of parameters. First approach was using Tree Classifier parameter weights extracted from trained classifier usign full variable set. \n",
    "\n",
    "#### Here is list of parameters with non-zero values:\n",
    "\n",
    "|Parameter|Weight|\n",
    "|---|---|\n",
    "|from_poi_ratio|0.410935|\n",
    "|total_stock_value|0.188715|\n",
    "|bonus|0.124453|\n",
    "|shared_receipt_with_poi|0.106765|\n",
    "|to_messages|0.105462|\n",
    "|restricted_stock|0.063670|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My second approach was finding variables having > 0.9 correlation with poi and >0.9 correlation with those that have >0.9 correlation with poi, and so forth until a depth value. I used a depth of 1. \n",
    "\n",
    "I did not use any scaling, knowing scaling would have no effect on tree classifiers which I believed will be optimal predictors for this project. However, I filled missing values each with a **GaussianNB** predictor that used all parameters other than the original one plus the **poi** parameter. Later on the predictions from **GaussianNB** predictor are used to fill missing values.\n",
    "\n",
    "I created two new variables, one for **ratio of mails received from POIs**, and the other for **ratio of mail sent to POIs**. I believe the numbers of mails sent to POI or received thereof would not give meaningful info. SOme might be sending too many emails or too few emails overall. In this case, having the ratio for their POI related emails would provide better insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "> What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to try all classifiers including linear models with an added rounding layer. From Linear models GaussianNB, and Linear Regression, the predictors are used without parameter tuning, since they dont have parameter tuning. For Lasso and other regular classifiers, I used a set of parameters with Grid Search. All scores listed below belong to best parameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Feature Set Results:\n",
    "\n",
    "Classifier|Accuracy|Precision|Recall|F1 Score|F2 Score\n",
    "---|---|---|---|---|---\n",
    "GaussianNB|0.886|0.33|0.25|0.286|0.263\n",
    "Linear Regression|0.864|0.25|0.25|0.25|0.25\n",
    "Lasso|0.8636363636363636|0.25|0.25|0.25|0.25\n",
    "SVC|0.9090909090909091|0.0|0.0|0.0|0.0\n",
    "DecisionTreeClassifier|0.841|0.2|0.25|0.22|0.238\n",
    "RandomForestClassifier|0.932|1.0|0.25|0.4|0.294\n",
    "\n",
    "#### DecisionTreeClassifier Weights Feature Selector\n",
    "\n",
    "Classifier|Accuracy|Precision|Recall|F1 Score|F2 Score\n",
    "---|---|---|---|---|---\n",
    "GaussianNB|0.886|0.4|0.5|0.444|0.476\n",
    "Linear Regression|0.91|0.5|0.25|0.333|0.278\n",
    "Lasso|0.91|0.5|0.25|0.333|0.278\n",
    "SVC|0.91|0.0|0.0|0.0|0.0\n",
    "DecisionTreeClassifier|0.886|0.4|0.5|0.444|0.476\n",
    "RandomForestClassifier|0.864|0.0|0.0|0.0|0.0\n",
    "\n",
    "#### Correlation (depth = 1) Results:\n",
    "\n",
    "Classifier|Accuracy|Precision|Recall|F1 Score|F2 Score\n",
    "---|---|---|---|---|---\n",
    "GaussianNB|0.864|0.25|0.25|0.25|0.25\n",
    "Linear Regression|0.886|0.333|0.25|0.2865|0.263\n",
    "Lasso|0.91|0.5|0.25|0.333|0.278\n",
    "SVC|0.91|0.0|0.0|0.0|0.0\n",
    "DecisionTreeClassifier|0.91|0.5|1.0|0.67|0.833\n",
    "RandomForestClassifier|0.977|1.0|0.75|0.857|0.789\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation @ Depth = 1** gave best results with highest Recall score of DecisionTreeClassifier (100%) and highest Precision of RandomForestClassifier (100%). \n",
    "\n",
    "Since finding all POIs is more important than precisely finding correct POIs, the primary score is Recall. Therefore, I decided to go with **DecisionTreeClassifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "> What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers have a lot of parameters in order to decide their behaviors with fitting data and classifiying input. Each data will need different set of parameter values to classify input the most efficiently. Parameter tuning is trying to find this best parameters or getting close enough.\n",
    "\n",
    "For this project I went through list of parameters available for tuning for each classifier. Each classifier is then wrapped with GridSearch alongside with this parameter ranges. Gridsearch, then tries all combinations of these parameter valu lists, and returns the best predictor configuration.\n",
    "\n",
    "At the end of parameter tuning I decided to go with **DecisionTreeClassifier**. The best parameters found with this classifier are as below:\n",
    "\n",
    "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None\n",
    "        max_features=None, max_leaf_nodes=None,\n",
    "        min_impurity_split=1e-07, min_samples_leaf=5,\n",
    "        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "        presort=False, random_state=0, splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "> What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is testing the classifier / model built for the purpose or classifying new data. To do this, original data should be split into two groups: **train** and **test**\n",
    "\n",
    "Train data is used to build model/classifier. Test data is used to validate if the model behaves as expected. Test data is expected to be completely new to the classifier at the time testing. Test data can also be split into validation and test for bling testing. But in this project we only split data into train and test.\n",
    "\n",
    "In model building stage of this project we also split data into train and test. We first fitted out classifiers with train dataset. Later on we evaluated our classifiers based on test data. \n",
    "\n",
    "However this type of evaluation is not deterministic enough. To get results better evaluating classifier n-fold validation is used. In this method, data is reshuffled n times and tested with split results for each fold. Overall results are then combined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "> Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall:** The ratio of POIs being identified.\n",
    "\n",
    "**Precision:** The ratio of identified entries being POIs\n",
    "\n",
    "My DecisionTreeClassifier achieved following scores for these metrics:\n",
    "\n",
    "* Recall: **0.39800**\n",
    "\n",
    "* Precision: **0.46468**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from time import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectKBest, chi2\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# %load poi_id.py\n",
    "# %%writefile poi_id.py # run this when finished.\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "# TODO: when finished code from below blocks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first start with the full set and then decide whish parameters to continue with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = [\"poi\"] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "for k,v in data_dict['METTS MARK'].iteritems():\n",
    "    if k not in [\"poi\",\"email_address\"]:\n",
    "        features_list.append(k)\n",
    "print str(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "There is one value which is not actually a data point but a aggregation entry. It is total row in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': 26704229, 'to_messages': 'NaN', 'deferral_payments': 32083396, 'total_payments': 309886585, 'exercised_stock_options': 311764000, 'bonus': 97343619, 'restricted_stock': 130322299, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -7576788, 'total_stock_value': 434509511, 'expenses': 5235198, 'loan_advances': 83925000, 'from_messages': 'NaN', 'other': 42667589, 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 1398517, 'deferred_income': -27992891, 'long_term_incentive': 48521928, 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "print data_dict['TOTAL']\n",
    "del data_dict['TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>False</td>\n",
       "      <td>201955.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>False</td>\n",
       "      <td>477.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      poi    salary  to_messages  deferral_payments  \\\n",
       "ALLEN PHILLIP K     False  201955.0       2902.0          2869717.0   \n",
       "BADUM JAMES P       False       NaN          NaN           178980.0   \n",
       "BANNANTINE JAMES M  False     477.0        566.0                NaN   \n",
       "\n",
       "                    total_payments  exercised_stock_options      bonus  \\\n",
       "ALLEN PHILLIP K          4484442.0                1729541.0  4175000.0   \n",
       "BADUM JAMES P             182466.0                 257817.0        NaN   \n",
       "BANNANTINE JAMES M        916197.0                4046157.0        NaN   \n",
       "\n",
       "                    restricted_stock  shared_receipt_with_poi  \\\n",
       "ALLEN PHILLIP K             126027.0                   1407.0   \n",
       "BADUM JAMES P                    NaN                      NaN   \n",
       "BANNANTINE JAMES M         1757552.0                    465.0   \n",
       "\n",
       "                    restricted_stock_deferred  total_stock_value  expenses  \\\n",
       "ALLEN PHILLIP K                     -126027.0          1729541.0   13868.0   \n",
       "BADUM JAMES P                             NaN           257817.0    3486.0   \n",
       "BANNANTINE JAMES M                  -560222.0          5243487.0   56301.0   \n",
       "\n",
       "                    loan_advances  from_messages     other  \\\n",
       "ALLEN PHILLIP K               NaN         2195.0     152.0   \n",
       "BADUM JAMES P                 NaN            NaN       NaN   \n",
       "BANNANTINE JAMES M            NaN           29.0  864523.0   \n",
       "\n",
       "                    from_this_person_to_poi  director_fees  deferred_income  \\\n",
       "ALLEN PHILLIP K                        65.0            NaN       -3081055.0   \n",
       "BADUM JAMES P                           NaN            NaN              NaN   \n",
       "BANNANTINE JAMES M                      0.0            NaN          -5104.0   \n",
       "\n",
       "                    long_term_incentive  from_poi_to_this_person  \n",
       "ALLEN PHILLIP K                304805.0                     47.0  \n",
       "BADUM JAMES P                       NaN                      NaN  \n",
       "BANNANTINE JAMES M                  NaN                     39.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_dict).transpose()[features_list]\n",
    "df = df.replace('NaN', np.nan, regex=True)\n",
    "def is_NaN(x):\n",
    "    return x == 'NaN'\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.240000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>8.100000e+01</td>\n",
       "      <td>1.090000e+02</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.840875e+05</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>8.416025e+05</td>\n",
       "      <td>2.623421e+06</td>\n",
       "      <td>2.959559e+06</td>\n",
       "      <td>1.201773e+06</td>\n",
       "      <td>1.147424e+06</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>6.218928e+05</td>\n",
       "      <td>3.352073e+06</td>\n",
       "      <td>54192.010638</td>\n",
       "      <td>2.797500e+07</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>4.652767e+05</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>89822.875000</td>\n",
       "      <td>-5.810498e+05</td>\n",
       "      <td>7.464912e+05</td>\n",
       "      <td>64.895349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.771311e+05</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>1.289323e+06</td>\n",
       "      <td>9.488106e+06</td>\n",
       "      <td>5.499450e+06</td>\n",
       "      <td>1.441679e+06</td>\n",
       "      <td>2.249770e+06</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>3.845528e+06</td>\n",
       "      <td>6.532883e+06</td>\n",
       "      <td>46108.377454</td>\n",
       "      <td>4.638256e+07</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>1.389719e+06</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>41112.700735</td>\n",
       "      <td>9.420764e+05</td>\n",
       "      <td>8.629174e+05</td>\n",
       "      <td>86.979244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.787380e+06</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3285.000000</td>\n",
       "      <td>-3.504386e+06</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.118020e+05</td>\n",
       "      <td>541.250000</td>\n",
       "      <td>7.964450e+04</td>\n",
       "      <td>3.863802e+05</td>\n",
       "      <td>5.067650e+05</td>\n",
       "      <td>4.250000e+05</td>\n",
       "      <td>2.520550e+05</td>\n",
       "      <td>249.750000</td>\n",
       "      <td>-3.298250e+05</td>\n",
       "      <td>4.941360e+05</td>\n",
       "      <td>22479.000000</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>1.209000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83674.500000</td>\n",
       "      <td>-6.112092e+05</td>\n",
       "      <td>2.750000e+05</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.587410e+05</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>2.210635e+05</td>\n",
       "      <td>1.100246e+06</td>\n",
       "      <td>1.297049e+06</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>4.410960e+05</td>\n",
       "      <td>740.500000</td>\n",
       "      <td>-1.402640e+05</td>\n",
       "      <td>1.095040e+06</td>\n",
       "      <td>46547.500000</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.198450e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>106164.500000</td>\n",
       "      <td>-1.519270e+05</td>\n",
       "      <td>4.221580e+05</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.086065e+05</td>\n",
       "      <td>2634.750000</td>\n",
       "      <td>8.672112e+05</td>\n",
       "      <td>2.084663e+06</td>\n",
       "      <td>2.542813e+06</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>9.850320e+05</td>\n",
       "      <td>1888.250000</td>\n",
       "      <td>-7.241900e+04</td>\n",
       "      <td>2.606763e+06</td>\n",
       "      <td>78408.500000</td>\n",
       "      <td>4.176250e+07</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>3.575772e+05</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>112815.000000</td>\n",
       "      <td>-3.792600e+04</td>\n",
       "      <td>8.318090e+05</td>\n",
       "      <td>72.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.111258e+06</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>6.426990e+06</td>\n",
       "      <td>1.035598e+08</td>\n",
       "      <td>3.434838e+07</td>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>1.476169e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>4.911008e+07</td>\n",
       "      <td>228763.000000</td>\n",
       "      <td>8.152500e+07</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>1.035973e+07</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>137864.000000</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>5.145434e+06</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary   to_messages  deferral_payments  total_payments  \\\n",
       "count  9.400000e+01     86.000000       3.800000e+01    1.240000e+02   \n",
       "mean   2.840875e+05   2073.860465       8.416025e+05    2.623421e+06   \n",
       "std    1.771311e+05   2582.700981       1.289323e+06    9.488106e+06   \n",
       "min    4.770000e+02     57.000000      -1.025000e+05    1.480000e+02   \n",
       "25%    2.118020e+05    541.250000       7.964450e+04    3.863802e+05   \n",
       "50%    2.587410e+05   1211.000000       2.210635e+05    1.100246e+06   \n",
       "75%    3.086065e+05   2634.750000       8.672112e+05    2.084663e+06   \n",
       "max    1.111258e+06  15149.000000       6.426990e+06    1.035598e+08   \n",
       "\n",
       "       exercised_stock_options         bonus  restricted_stock  \\\n",
       "count             1.010000e+02  8.100000e+01      1.090000e+02   \n",
       "mean              2.959559e+06  1.201773e+06      1.147424e+06   \n",
       "std               5.499450e+06  1.441679e+06      2.249770e+06   \n",
       "min               3.285000e+03  7.000000e+04     -2.604490e+06   \n",
       "25%               5.067650e+05  4.250000e+05      2.520550e+05   \n",
       "50%               1.297049e+06  7.500000e+05      4.410960e+05   \n",
       "75%               2.542813e+06  1.200000e+06      9.850320e+05   \n",
       "max               3.434838e+07  8.000000e+06      1.476169e+07   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
       "count                86.000000               1.700000e+01       1.250000e+02   \n",
       "mean               1176.465116               6.218928e+05       3.352073e+06   \n",
       "std                1178.317641               3.845528e+06       6.532883e+06   \n",
       "min                   2.000000              -1.787380e+06      -4.409300e+04   \n",
       "25%                 249.750000              -3.298250e+05       4.941360e+05   \n",
       "50%                 740.500000              -1.402640e+05       1.095040e+06   \n",
       "75%                1888.250000              -7.241900e+04       2.606763e+06   \n",
       "max                5521.000000               1.545629e+07       4.911008e+07   \n",
       "\n",
       "            expenses  loan_advances  from_messages         other  \\\n",
       "count      94.000000   3.000000e+00      86.000000  9.200000e+01   \n",
       "mean    54192.010638   2.797500e+07     608.790698  4.652767e+05   \n",
       "std     46108.377454   4.638256e+07    1841.033949  1.389719e+06   \n",
       "min       148.000000   4.000000e+05      12.000000  2.000000e+00   \n",
       "25%     22479.000000   1.200000e+06      22.750000  1.209000e+03   \n",
       "50%     46547.500000   2.000000e+06      41.000000  5.198450e+04   \n",
       "75%     78408.500000   4.176250e+07     145.500000  3.575772e+05   \n",
       "max    228763.000000   8.152500e+07   14368.000000  1.035973e+07   \n",
       "\n",
       "       from_this_person_to_poi  director_fees  deferred_income  \\\n",
       "count                86.000000      16.000000     4.800000e+01   \n",
       "mean                 41.232558   89822.875000    -5.810498e+05   \n",
       "std                 100.073111   41112.700735     9.420764e+05   \n",
       "min                   0.000000    3285.000000    -3.504386e+06   \n",
       "25%                   1.000000   83674.500000    -6.112092e+05   \n",
       "50%                   8.000000  106164.500000    -1.519270e+05   \n",
       "75%                  24.750000  112815.000000    -3.792600e+04   \n",
       "max                 609.000000  137864.000000    -8.330000e+02   \n",
       "\n",
       "       long_term_incentive  from_poi_to_this_person  \n",
       "count         6.500000e+01                86.000000  \n",
       "mean          7.464912e+05                64.895349  \n",
       "std           8.629174e+05                86.979244  \n",
       "min           6.922300e+04                 0.000000  \n",
       "25%           2.750000e+05                10.000000  \n",
       "50%           4.221580e+05                35.000000  \n",
       "75%           8.318090e+05                72.250000  \n",
       "max           5.145434e+06               528.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features_list[1:]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe0bf2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "sns.heatmap(abs(corr), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "def map_(x):\n",
    "    if abs(x)>0.9:\n",
    "        return x\n",
    "    return 0\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(abs(corr.applymap(map_)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe0dd358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAKmCAYAAAArcaqQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdfec550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_(x):\n",
    "    if abs(x)==1:\n",
    "        return 0\n",
    "    elif abs(x)>0.9:\n",
    "        return x\n",
    "    return 0\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(abs(corr.applymap(map_)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_parameters_by_correlation(corr, min_corr, depth, selections):\n",
    "    features = corr.columns.values.tolist()\n",
    "    new_selections = []\n",
    "    for sel in selections:\n",
    "        for f in features:\n",
    "            if (sel != f) and (f not in selections+new_selections) and (f in corr) and (abs(corr[sel][f]) > min_corr):\n",
    "                new_selections.append(f)\n",
    "    selections = selections+new_selections\n",
    "    if depth < 1:\n",
    "        return selections\n",
    "    else:\n",
    "        return extract_parameters_by_correlation(corr, min_corr, depth-1, selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'loan_advances',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'exercised_stock_options',\n",
       " 'bonus',\n",
       " 'restricted_stock',\n",
       " 'total_stock_value',\n",
       " 'other',\n",
       " 'from_this_person_to_poi',\n",
       " 'deferred_income',\n",
       " 'long_term_incentive']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_components = extract_parameters_by_correlation(corr, 0.9,1, [\"poi\"])\n",
    "primary_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove NaNs from train data:\n",
    "def clean_train_data(features):\n",
    "    for line in features:\n",
    "        for i,v in enumerate(line):\n",
    "            if np.isnan(v):\n",
    "                line[i] = -1.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_na_values(df, column):\n",
    "    print(\"Predicting missing values for {}.\".format(column)) \n",
    "    columns = df.columns.values.tolist()\n",
    "    columns.remove(column)\n",
    "    # do not translate poi info into missing variables\n",
    "    columns.remove(\"poi\")\n",
    "    ok = df[df[column].notnull()]\n",
    "    ok_features = clean_train_data(ok[columns].values.tolist())\n",
    "    ok_labels = ok[column].values.tolist()\n",
    "    nok = df[df[column].isnull()]\n",
    "    if len(nok)<1:\n",
    "        print(\"No missing values for {}!\".format(column))\n",
    "        return\n",
    "    clf_g = GaussianNB()\n",
    "    clf_g.fit(ok_features,ok_labels)\n",
    "    nok_features = clean_train_data(nok[columns].values.tolist())\n",
    "    pred = clf_g.predict(nok_features)\n",
    "    df.loc[nok.index,column] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting missing values for salary.\n",
      "Predicting missing values for to_messages.\n",
      "Predicting missing values for deferral_payments.\n",
      "Predicting missing values for total_payments.\n",
      "Predicting missing values for exercised_stock_options.\n",
      "Predicting missing values for bonus.\n",
      "Predicting missing values for restricted_stock.\n",
      "Predicting missing values for shared_receipt_with_poi.\n",
      "Predicting missing values for restricted_stock_deferred.\n",
      "Predicting missing values for total_stock_value.\n",
      "Predicting missing values for expenses.\n",
      "Predicting missing values for loan_advances.\n",
      "Predicting missing values for from_messages.\n",
      "Predicting missing values for other.\n",
      "Predicting missing values for from_this_person_to_poi.\n",
      "Predicting missing values for director_fees.\n",
      "Predicting missing values for deferred_income.\n",
      "Predicting missing values for long_term_incentive.\n",
      "Predicting missing values for from_poi_to_this_person.\n"
     ]
    }
   ],
   "source": [
    "### Fill missing fields with predictions\n",
    "for column in df.columns.values.tolist():\n",
    "    ## Do not predict poi \n",
    "    if column != \"poi\":\n",
    "        predict_na_values(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "\n",
    "# Create new feaures\n",
    "df['from_poi_ratio'] = df['from_poi_to_this_person']/df['to_messages']\n",
    "df['to_poi_ratio'] = df['from_this_person_to_poi']/df['from_messages']\n",
    "\n",
    "my_dataset = df.to_dict(orient='index')\n",
    "final_feature_list = primary_components+['from_poi_ratio','to_poi_ratio']\n",
    "#final_feature_list = features_list + ['from_poi_ratio', 'to_poi_ratio']\n",
    "\n",
    "## parameters weigths extracted from full set\n",
    "#final_feature_list = [\"poi\",\"from_poi_ratio\",\"total_stock_value\",\"bonus\",\"shared_receipt_with_poi\",\"to_messages\",\"restricted_stock\"]\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, final_feature_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "clf_g = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf_ln = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts_l = {\n",
    "    \"alpha\":[0.6,0.85,0.95,1.0],\n",
    "    \"fit_intercept\":[True,False]\n",
    "}\n",
    "clf_l = GridSearchCV(Lasso(), opts_l)\n",
    "#regression.fit(features, labels)\n",
    "#pd.DataFrame(zip(features_list_,regression.coef_),columns=[\"name\",\"coef\"]).sort(['coef','name'], ascending=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "opts_s = {\n",
    "    \"C\":[0.1,1.0,10.0],\n",
    "    #\"kernel\":[\"linear\", \"poly\", \"rbf\"]\n",
    "}\n",
    "clf_s = GridSearchCV(svm.SVC(),opts_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts_t = {\n",
    "    \"criterion\":[\"gini\",\"entropy\"],\n",
    "    \"min_samples_leaf\":[1,2,5],\n",
    "    \"min_samples_split\":[2,4,10]\n",
    "}\n",
    "clf_t = GridSearchCV(DecisionTreeClassifier(random_state=42), opts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts_f = {\n",
    "    \"criterion\":[\"gini\",\"entropy\"],\n",
    "    \"n_estimators\":[5,10,30,100,200],\n",
    "    \"min_samples_leaf\":[1,2,5],\n",
    "    \"min_samples_split\":[2,4,10]\n",
    "}\n",
    "clf_f = GridSearchCV(RandomForestClassifier(random_state = 42), opts_f)\n",
    "#print(\"Accuracy: {:.2f}% {}\".format(model_predictor(clf)*100, (k+1)*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.model_selection  import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  2.00000000e+06,   1.02590000e+04,   9.10930000e+04,\n",
       "          3.07660640e+07,   1.00000000e+06,   1.26027000e+05,\n",
       "          3.07660640e+07,   2.85600000e+03,   4.00000000e+00,\n",
       "         -3.00000000e+05,   1.61701100e+06,   4.64088398e-02,\n",
       "          1.11111111e-01]),\n",
       " array([  4.00000000e+05,   7.31220000e+04,   1.10139300e+06,\n",
       "          1.17551000e+05,   8.00000000e+05,   3.78082000e+05,\n",
       "          4.95633000e+05,   4.94000000e+02,   4.00000000e+00,\n",
       "         -4.12500000e+04,   1.75000000e+05,   0.00000000e+00,\n",
       "          1.21212121e-01])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "selector = SelectKBest(chi2,k=10)\n",
    "selector.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"name\":\"GaussianNB\",\"predictor\":clf_g},\n",
    "    {\"name\":\"Linear Regression\",\"predictor\":clf_ln},\n",
    "    {\"name\":\"Lasso\",\"predictor\":clf_l},\n",
    "    {\"name\":\"SVC\",\"predictor\":clf_s},\n",
    "    {\"name\":\"DecisionTreeClassifier\",\"predictor\":clf_t},\n",
    "    {\"name\":\"RandomForestClassifier\",\"predictor\":clf_f}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores for Linear Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "clf_g.fit(features_train, labels_train)\n",
    "clf_ln.fit(features_train, labels_train)\n",
    "print \"GaussianNB score:  {}\".format(clf_g.score(features_test, labels_test))\n",
    "print \"Linear Regression score:  {}\".format(clf_ln.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores for Other Models w/ Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_pred(x):\n",
    "    if x>=0.5:\n",
    "        return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(predictions,truth):\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    true_positives = 0\n",
    "    for prediction, truth in zip(predictions, labels_test):\n",
    "        p_int = round_pred(prediction)\n",
    "        if p_int == 0 and truth == 0:\n",
    "            true_negatives += 1\n",
    "        elif p_int == 0 and truth == 1:\n",
    "            false_negatives += 1\n",
    "        elif p_int == 1 and truth == 0:\n",
    "            false_positives += 1\n",
    "        elif p_int == 1 and truth == 1:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            print \"Warning: Found a predicted label not == 0 or 1. value:{}\".format(str(prediction))\n",
    "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "    precision = 1.0*true_positives/(true_positives+false_positives+0.000001)\n",
    "    recall = 1.0*true_positives/(true_positives+false_negatives+0.000001)\n",
    "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives+0.000001)\n",
    "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall+0.000001)\n",
    "    return [accuracy, precision, recall, f1, f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_predictor(classifier):\n",
    "    classifier.fit(features_train, labels_train)\n",
    "    y_pred = classifier.predict(features_test)\n",
    "    accuracy, precision, recall, f1, f2 = get_scores(y_pred,labels_test)\n",
    "    return [accuracy, precision, recall, f1, f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_predictors():\n",
    "    params = {}\n",
    "    scores = []\n",
    "    for predictor in models:\n",
    "        accuracy, precision, recall, f1, f2 = model_predictor(predictor[\"predictor\"])\n",
    "        scores.append([predictor[\"name\"], accuracy, precision, recall, f1, f2])\n",
    "        # print(\"{} accuracy: {:.2f}, precision: {:.2f}, recall: {:.2f}, F1: {:.2f}, F2: {:.2f}\".format(predictor[\"name\"], accuracy, precision, recall, f1, f2))\n",
    "        if hasattr(predictor[\"predictor\"],\"best_estimator_\"):\n",
    "            params[predictor[\"name\"]] = predictor[\"predictor\"].best_estimator_\n",
    "        else:\n",
    "            params[predictor[\"name\"]] = predictor[\"predictor\"]\n",
    "        score_table = pd.DataFrame(scores, columns=[\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"F2 Score\"])\n",
    "    return params, score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.294117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy  Precision  Recall  F1 Score  F2 Score\n",
       "0              GaussianNB  0.863636   0.250000    0.25  0.250000  0.250000\n",
       "1       Linear Regression  0.886364   0.333333    0.25  0.285714  0.263158\n",
       "2                   Lasso  0.909091   0.500000    0.25  0.333333  0.277778\n",
       "3                     SVC  0.909091   0.000000    0.00  0.000000  0.000000\n",
       "4  DecisionTreeClassifier  0.954545   1.000000    0.50  0.666667  0.555555\n",
       "5  RandomForestClassifier  0.931818   0.999999    0.25  0.400000  0.294117"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, score_table = run_predictors()\n",
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pandas_df_to_markdown_table(df):\n",
    "    from IPython.display import Markdown, display\n",
    "    fmt = ['---' for i in range(len(df.columns))]\n",
    "    df_fmt = pd.DataFrame([fmt], columns=df.columns)\n",
    "    df_formatted = pd.concat([df_fmt, df])\n",
    "    return df_formatted.to_csv(sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"DecisionTreeClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from_poi_ratio</td>\n",
       "      <td>0.278774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>0.263039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>0.174847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan_advances</td>\n",
       "      <td>0.088824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>0.069320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from_this_person_to_poi</td>\n",
       "      <td>0.063640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bonus</td>\n",
       "      <td>0.061556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter    Weight\n",
       "0           from_poi_ratio  0.278774\n",
       "1        total_stock_value  0.263039\n",
       "2  exercised_stock_options  0.174847\n",
       "3            loan_advances  0.088824\n",
       "4                    other  0.069320\n",
       "5  from_this_person_to_poi  0.063640\n",
       "6                    bonus  0.061556"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "weights = zip(final_feature_list,params[\"DecisionTreeClassifier\"].feature_importances_)\n",
    "weights_df = pd.DataFrame(sorted(weights, key=itemgetter(1), reverse=True), columns=[\"Parameter\", \"Weight\"])\n",
    "weights_df[weights_df[\"Weight\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    presort=False, random_state=42, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, final_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best')\n",
      "\tAccuracy: 0.85860\tPrecision: 0.46468\tRecall: 0.39800\tF1: 0.42876\tF2: 0.40976\n",
      "\tTotal predictions: 15000\tTrue positives:  796\tFalse positives:  917\tFalse negatives: 1204\tTrue negatives: 12083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load tester.py\n",
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
